{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring how to setup the Twitter API\n",
    "\n",
    "- The code is currently really dirty and is basically a copy-past from https://towardsdatascience.com/python-identifying-twitter-influencers-through-network-analysis-964c9b293e03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tweepy\n",
    "import igraph\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import ast\n",
    "from operator import itemgetter\n",
    "from igraph import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are mine, I guess you should create your own developer account. \n",
    "CONSUMER_KEY = 'JbQ88IvxR7pAqtiGN9V2gcEfT'\n",
    "CONSUMER_SECRET_KEY = 'KtbFDwFfub5QzBmyUxpxdvOMR0kfS4u2i2C4T82jrDSTinP74Q'\n",
    "\n",
    "ACCESS_TOKEN = '1074946114917404672-em24Gf9a9Ouc5907wJhvmmAn75qeZy'\n",
    "ACCESS_SECRET_TOKEN = 'nDfuT1tO7Ub2QLie4AasUGkvagS7nHKB9L65gJFjS79iH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetGrabber():\n",
    "    \n",
    "    def __init__(self,myApi,sApi,at,sAt):\n",
    "        self.tweepy = tweepy\n",
    "        auth = tweepy.OAuthHandler(myApi, sApi)\n",
    "        auth.set_access_token(at, sAt)\n",
    "        self.api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "    #Return the string without non ASCII characters\n",
    "    def strip_non_ascii(self,string):\n",
    "        stripped = (c for c in string if 0 < ord(c) < 127)\n",
    "        return ''.join(stripped)  \n",
    "\n",
    "    def user_search(self,user,csv_prefix):\n",
    "        API_results = self.tweepy.Cursor(self.api.user_timeline,id=user,tweet_mode='extended').items()\n",
    "        with open(f'{csv_prefix}.csv', 'w', newline='') as csvfile:\n",
    "            fieldnames = ['tweet_id', 'tweet_text', 'date', 'user_id', 'user_mentions', 'retweet_count']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "\n",
    "            for tweet in API_results:\n",
    "                text = self.strip_non_ascii(tweet.full_text)\n",
    "                date = tweet.created_at.strftime('%m/%d/%Y')        \n",
    "                writer.writerow(\n",
    "                  {\n",
    "                    'tweet_id': tweet.id_str,\n",
    "                    'tweet_text': text,\n",
    "                    'date': date,\n",
    "                    'user_id': tweet.user.id_str,\n",
    "                    'user_mentions':tweet.entities['user_mentions'],\n",
    "                    'retweet_count': tweet.retweet_count\n",
    "                    }\n",
    "                )\n",
    "\n",
    "# Process the created CSV in order to generate edge list\n",
    "class RetweetParser():\n",
    "    \n",
    "    def __init__(self,data,user):\n",
    "        self.user = user\n",
    "\n",
    "        edge_list = []\n",
    "  \n",
    "        for idx,row in data.iterrows():\n",
    "            if len(row[4]) > 5:    \n",
    "                user_account = user\n",
    "                weight = np.log(row[5] + 1)\n",
    "                for idx_1, item in enumerate(ast.literal_eval(row[4])):\n",
    "                    edge_list.append((user_account,item['screen_name'],weight))\n",
    "\n",
    "                    for idx_2 in range(idx_1+1,len(ast.literal_eval(row[4]))):\n",
    "                        name_a = ast.literal_eval(row[4])[idx_1]['screen_name']\n",
    "                        name_b = ast.literal_eval(row[4])[idx_2]['screen_name']\n",
    "\n",
    "                        edge_list.append((name_a,name_b,weight))\n",
    "      \n",
    "        with open(f'{self.user}.csv', 'w', newline='') as csvfile:\n",
    "            fieldnames = ['user_a', 'user_b', 'log_retweet']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "\n",
    "            for row in edge_list:        \n",
    "                writer.writerow({\n",
    "                              'user_a': row[0],\n",
    "                              'user_b': row[1],\n",
    "                              'log_retweet': row[2]\n",
    "                              })\n",
    "\n",
    "\n",
    "# Eigenvector centrality measures 'influence' of each node within the graph network\n",
    "class TweetGraph():\n",
    "    def __init__(self,edge_list):\n",
    "        data = pd.read_csv(edge_list).to_records(index=False)\n",
    "        self.tuple_graph = igraph.Graph.TupleList(data, weights=True, directed=False)\n",
    "        \n",
    "    def e_centrality(self):\n",
    "        vectors = self.tuple_graph.eigenvector_centrality()\n",
    "        e = {name:cen for cen, name in  zip([v for v in vectors],self.tuple_graph.vs['name'])}\n",
    "        return sorted(e.items(), key=operator.itemgetter(1),reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building gml... <__main__.TweetGraph object at 0x7fd3f0ac3e10>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'IGRAPH UNW- 21 92 -- \\n+ attr: name (v), size (v), weight (e)'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = TweetGrabber(\n",
    "  myApi=CONSUMER_KEY,\n",
    "  sApi=CONSUMER_SECRET_KEY,\n",
    "  at=ACCESS_TOKEN,\n",
    "  sAt=ACCESS_SECRET_TOKEN\n",
    ")\n",
    "\n",
    "# screen_name = 125815552\n",
    "screen_name = 'GuillaumeJaume'\n",
    "t.user_search(user=screen_name, csv_prefix=screen_name)\n",
    "\n",
    "# Read the created CSV into a pandas DataFrame for input to RetweetParser class\n",
    "userFrame = pd.read_csv(screen_name + \".csv\")\n",
    "\n",
    "# RetweetParser overwrites the first CSV with a weighted edgelist\n",
    "r = RetweetParser(userFrame, screen_name)\n",
    "\n",
    "# The weighted, undirected iGraph object\n",
    "log_graph = TweetGraph(edge_list= screen_name + \".csv\")\n",
    "\n",
    "# Add 'size' attribute to each vertex based on its Eigencentrality\n",
    "# NOTE: multiplying the value by some consistent large number creates a more intuitive\n",
    "# plot, viewing-wise, but doesn't impact classification, since this change is applied\n",
    "# to all vertices\n",
    "for key, value in log_graph.e_centrality():\n",
    "    log_graph.tuple_graph.vs.find(name=key)['size'] = value*20\n",
    "\n",
    "# Save the graph in GML format\n",
    "print(\"Building gml...\", log_graph)\n",
    "log_graph.tuple_graph.write_gml(f=screen_name+\".gml\")\n",
    "\n",
    "log_graph.tuple_graph.summary()\n",
    "#Plot the graph for viewing\n",
    "# style = {}\n",
    "# style[\"edge_curved\"] = False\n",
    "# style[\"vertex_label\"] = log_graph.tuple_graph.vs['name']\n",
    "# style[\"vertex_label_size\"] = 5\n",
    "# plot(log_graph.tuple_graph, **style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
